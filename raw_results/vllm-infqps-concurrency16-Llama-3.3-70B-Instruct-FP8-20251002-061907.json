{"date": "20251002-061907", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 16, "duration": 48.016080991132185, "completed": 256, "total_input_tokens": 261888, "total_output_tokens": 77653, "request_throughput": 5.3315471549475095, "request_goodput": null, "output_throughput": 1617.2290282153865, "total_token_throughput": 7071.401767726689, "max_output_tokens_per_s": 1815.0, "max_concurrent_requests": 28, "mean_ttft_ms": 209.92302996000944, "median_ttft_ms": 189.76409803144634, "std_ttft_ms": 75.16611729101851, "p99_ttft_ms": 488.9279089751653, "mean_tpot_ms": 8.678135358139997, "median_tpot_ms": 8.81265673750862, "std_tpot_ms": 0.583411546032222, "p99_tpot_ms": 8.955411455646917, "mean_itl_ms": 8.788271579962053, "median_itl_ms": 8.676318917423487, "std_itl_ms": 1.5588245286672127, "p99_itl_ms": 13.10556706041093, "mean_e2el_ms": 2866.8987809460305, "median_e2el_ms": 2753.5123539855704, "std_e2el_ms": 1765.613891458711, "p99_e2el_ms": 4969.585377140902}