{"date": "20251002-052140", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 64, "duration": 6.890980022959411, "completed": 256, "total_input_tokens": 130816, "total_output_tokens": 28177, "request_throughput": 37.150013372126686, "request_goodput": null, "output_throughput": 4088.9684640094283, "total_token_throughput": 23072.625297166167, "max_output_tokens_per_s": 5376.0, "max_concurrent_requests": 125, "mean_ttft_ms": 284.37052801928075, "median_ttft_ms": 212.81978150364012, "std_ttft_ms": 168.39715661020745, "p99_ttft_ms": 621.7739610001445, "mean_tpot_ms": 11.492725649142951, "median_tpot_ms": 11.637692413050829, "std_tpot_ms": 0.6916741333642452, "p99_tpot_ms": 12.585536986066405, "mean_itl_ms": 11.519413067669756, "median_itl_ms": 10.893419152125716, "std_itl_ms": 3.5929820294292365, "p99_itl_ms": 24.36398430727416, "mean_e2el_ms": 1540.7513326144908, "median_e2el_ms": 1678.38108795695, "std_e2el_ms": 500.96885941238435, "p99_e2el_ms": 2082.969010085799}