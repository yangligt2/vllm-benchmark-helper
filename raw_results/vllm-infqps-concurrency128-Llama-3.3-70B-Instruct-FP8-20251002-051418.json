{"date": "20251002-051418", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 512, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 128, "duration": 6.68839995097369, "completed": 512, "total_input_tokens": 261632, "total_output_tokens": 30782, "request_throughput": 76.55044610863375, "request_goodput": null, "output_throughput": 4602.296547101492, "total_token_throughput": 43719.57450861333, "max_output_tokens_per_s": 7519.0, "max_concurrent_requests": 254, "mean_ttft_ms": 607.496993804034, "median_ttft_ms": 606.7134229233488, "std_ttft_ms": 284.07542517837646, "p99_ttft_ms": 988.1937952106819, "mean_tpot_ms": 15.508611733571472, "median_tpot_ms": 16.145303097021365, "std_tpot_ms": 2.3788450297555483, "p99_tpot_ms": 21.31211744854225, "mean_itl_ms": 15.406474216263046, "median_itl_ms": 14.214789029210806, "std_itl_ms": 7.937472927972473, "p99_itl_ms": 52.90019313106316, "mean_e2el_ms": 1518.3443943606107, "median_e2el_ms": 1622.1608680207282, "std_e2el_ms": 406.51059906578365, "p99_e2el_ms": 2007.1454154280946}