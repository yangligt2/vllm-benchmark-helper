{"date": "20251002-074151", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 32, "duration": 28.488503285916522, "completed": 256, "total_input_tokens": 1048320, "total_output_tokens": 50390, "request_throughput": 8.986081066833556, "request_goodput": null, "output_throughput": 1768.783691241183, "total_token_throughput": 38566.78565992459, "max_output_tokens_per_s": 2453.0, "max_concurrent_requests": 50, "mean_ttft_ms": 1260.9207032719496, "median_ttft_ms": 1129.3532775016502, "std_ttft_ms": 662.569397679331, "p99_ttft_ms": 3300.0596674741246, "mean_tpot_ms": 10.273274411177548, "median_tpot_ms": 10.45862040847686, "std_tpot_ms": 0.8335802538903812, "p99_tpot_ms": 11.174309021569933, "mean_itl_ms": 10.347478727749301, "median_itl_ms": 10.287699988111854, "std_itl_ms": 2.0537403668938388, "p99_itl_ms": 17.163963702041652, "mean_e2el_ms": 3287.328350298594, "median_e2el_ms": 3429.4332360150293, "std_e2el_ms": 1094.658642367929, "p99_e2el_ms": 5936.139916419052}