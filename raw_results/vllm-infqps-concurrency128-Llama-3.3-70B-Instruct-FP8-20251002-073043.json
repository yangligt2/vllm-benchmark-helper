{"date": "20251002-073043", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 512, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 128, "duration": 52.71067759604193, "completed": 512, "total_input_tokens": 1048064, "total_output_tokens": 288607, "request_throughput": 9.713401977561492, "request_goodput": null, "output_throughput": 5475.304305738457, "total_token_throughput": 25358.638153806834, "max_output_tokens_per_s": 7412.0, "max_concurrent_requests": 152, "mean_ttft_ms": 1078.6841111030299, "median_ttft_ms": 761.8860349757597, "std_ttft_ms": 801.5053785258891, "p99_ttft_ms": 3284.756579191889, "mean_tpot_ms": 18.577717498379094, "median_tpot_ms": 18.218160969836806, "std_tpot_ms": 2.6097486479149405, "p99_tpot_ms": 23.92294555478529, "mean_itl_ms": 18.616037402526473, "median_itl_ms": 16.821398865431547, "std_itl_ms": 11.174572770205568, "p99_itl_ms": 65.68508909549563, "mean_e2el_ms": 11553.658996887862, "median_e2el_ms": 7850.641798460856, "std_e2el_ms": 8248.58401604432, "p99_e2el_ms": 23351.541283719707}