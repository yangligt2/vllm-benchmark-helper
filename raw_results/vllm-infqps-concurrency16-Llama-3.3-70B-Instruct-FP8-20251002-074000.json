{"date": "20251002-074000", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 16, "duration": 51.09147780598141, "completed": 256, "total_input_tokens": 1048320, "total_output_tokens": 49280, "request_throughput": 5.010620381194561, "request_goodput": null, "output_throughput": 964.5444233799528, "total_token_throughput": 21483.03488437168, "max_output_tokens_per_s": 1421.0, "max_concurrent_requests": 25, "mean_ttft_ms": 1046.9183509076174, "median_ttft_ms": 970.636795507744, "std_ttft_ms": 383.7999523721821, "p99_ttft_ms": 2289.8052236763756, "mean_tpot_ms": 10.576639519123777, "median_tpot_ms": 10.87525593625601, "std_tpot_ms": 1.3629961375018003, "p99_tpot_ms": 12.274302560215428, "mean_itl_ms": 10.845432511308777, "median_itl_ms": 9.032694506458938, "std_itl_ms": 10.43250709213401, "p99_itl_ms": 62.25337262265382, "mean_e2el_ms": 3123.8184124422332, "median_e2el_ms": 3449.4060130091384, "std_e2el_ms": 1008.609664481005, "p99_e2el_ms": 4804.094441223423}