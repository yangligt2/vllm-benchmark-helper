{"date": "20251002-041727", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 32, "duration": 3.143479803809896, "completed": 256, "total_input_tokens": 65280, "total_output_tokens": 3952, "request_throughput": 81.43841092591978, "request_goodput": null, "output_throughput": 1257.2054686688866, "total_token_throughput": 22024.000254778428, "max_output_tokens_per_s": 1421.0, "max_concurrent_requests": 114, "mean_ttft_ms": 205.8820971087698, "median_ttft_ms": 188.8081234646961, "std_ttft_ms": 63.93553308255376, "p99_ttft_ms": 376.77983489120373, "mean_tpot_ms": 11.71526154403508, "median_tpot_ms": 11.957077666496236, "std_tpot_ms": 1.178125205088621, "p99_tpot_ms": 13.495065729754668, "mean_itl_ms": 11.730498064234268, "median_itl_ms": 10.271108010783792, "std_itl_ms": 4.703469224696578, "p99_itl_ms": 30.029702128376815, "mean_e2el_ms": 375.2409664348306, "median_e2el_ms": 369.1586173372343, "std_e2el_ms": 73.71223994691027, "p99_e2el_ms": 530.6183384382166}