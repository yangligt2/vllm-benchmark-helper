{"date": "20251002-044333", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 16, "duration": 19.287214826093987, "completed": 256, "total_input_tokens": 65280, "total_output_tokens": 30432, "request_throughput": 13.273041354506688, "request_goodput": null, "output_throughput": 1577.8327910169826, "total_token_throughput": 4962.458336416188, "max_output_tokens_per_s": 1802.0, "max_concurrent_requests": 34, "mean_ttft_ms": 131.62567549898085, "median_ttft_ms": 122.04749882221222, "std_ttft_ms": 30.699150879616084, "p99_ttft_ms": 240.78628753777593, "mean_tpot_ms": 8.770754366228664, "median_tpot_ms": 8.812094701263378, "std_tpot_ms": 0.1679545621793852, "p99_tpot_ms": 9.15597884379553, "mean_itl_ms": 8.768094951678378, "median_itl_ms": 8.535494562238455, "std_itl_ms": 1.713007727988903, "p99_itl_ms": 14.160159102175385, "mean_e2el_ms": 1165.1646559394067, "median_e2el_ms": 1239.8254059953615, "std_e2el_ms": 241.95750547050486, "p99_e2el_ms": 1327.8982995077968}