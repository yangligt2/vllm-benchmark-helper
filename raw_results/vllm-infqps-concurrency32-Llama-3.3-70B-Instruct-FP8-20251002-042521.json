{"date": "20251002-042521", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 32, "duration": 4.3185866789426655, "completed": 256, "total_input_tokens": 65280, "total_output_tokens": 7957, "request_throughput": 59.27865272410773, "request_goodput": null, "output_throughput": 1842.500936428614, "total_token_throughput": 16958.557381076087, "max_output_tokens_per_s": 2019.0, "max_concurrent_requests": 97, "mean_ttft_ms": 177.21045608504937, "median_ttft_ms": 159.30076397489756, "std_ttft_ms": 60.70441612828843, "p99_ttft_ms": 349.07879903912544, "mean_tpot_ms": 11.201225037811813, "median_tpot_ms": 11.309292242531816, "std_tpot_ms": 0.780074192103758, "p99_tpot_ms": 12.389313568916894, "mean_itl_ms": 11.186823619862418, "median_itl_ms": 10.306719923391938, "std_itl_ms": 3.5470666237661344, "p99_itl_ms": 23.664817214012146, "mean_e2el_ms": 513.7326259564361, "median_e2el_ms": 510.6663630576804, "std_e2el_ms": 78.79314214688549, "p99_e2el_ms": 652.3655801196583}