{"date": "20251002-042636", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 64, "duration": 3.015593406977132, "completed": 256, "total_input_tokens": 65280, "total_output_tokens": 7846, "request_throughput": 84.89208107687752, "request_goodput": null, "output_throughput": 2601.8096411296133, "total_token_throughput": 24249.290315733382, "max_output_tokens_per_s": 2902.0, "max_concurrent_requests": 163, "mean_ttft_ms": 289.97169734975614, "median_ttft_ms": 243.11107699759305, "std_ttft_ms": 157.30678556946177, "p99_ttft_ms": 610.7399769593029, "mean_tpot_ms": 13.157687369614756, "median_tpot_ms": 13.428616164732844, "std_tpot_ms": 1.3405188374261736, "p99_tpot_ms": 14.907677158442958, "mean_itl_ms": 13.19200410823582, "median_itl_ms": 11.425778619013727, "std_itl_ms": 6.334553477572145, "p99_itl_ms": 40.41641143616287, "mean_e2el_ms": 681.0938268254176, "median_e2el_ms": 646.3127995375544, "std_e2el_ms": 177.52496718289046, "p99_e2el_ms": 995.0285130064003}