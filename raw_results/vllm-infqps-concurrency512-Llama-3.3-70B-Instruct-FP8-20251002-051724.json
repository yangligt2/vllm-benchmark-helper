{"date": "20251002-051724", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 2048, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 512, "duration": 17.80023482698016, "completed": 2048, "total_input_tokens": 1046528, "total_output_tokens": 122053, "request_throughput": 115.05466191354998, "request_goodput": null, "output_throughput": 6856.819653581307, "total_token_throughput": 65649.75189140535, "max_output_tokens_per_s": 12231.0, "max_concurrent_requests": 824, "mean_ttft_ms": 1998.088428787355, "median_ttft_ms": 2011.141387396492, "std_ttft_ms": 660.2651559433818, "p99_ttft_ms": 3489.1363232978615, "mean_tpot_ms": 34.1747788241679, "median_tpot_ms": 35.352007428642416, "std_tpot_ms": 8.464225291004725, "p99_tpot_ms": 46.133625562790606, "mean_itl_ms": 34.240380058905615, "median_itl_ms": 29.196429066359997, "std_itl_ms": 23.85654957213488, "p99_itl_ms": 124.8226864915339, "mean_e2el_ms": 4004.44414356798, "median_e2el_ms": 3980.8564729755744, "std_e2el_ms": 967.2164905972858, "p99_e2el_ms": 5855.67120448919}