{"date": "20251002-043907", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 512, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 128, "duration": 5.9252382658887655, "completed": 512, "total_input_tokens": 130560, "total_output_tokens": 31302, "request_throughput": 86.41002724692991, "request_goodput": null, "output_throughput": 5282.825532975391, "total_token_throughput": 27317.38248094252, "max_output_tokens_per_s": 6685.0, "max_concurrent_requests": 257, "mean_ttft_ms": 411.38252060864033, "median_ttft_ms": 347.6232908433303, "std_ttft_ms": 207.59842254762628, "p99_ttft_ms": 875.0432370044291, "mean_tpot_ms": 16.095387528071576, "median_tpot_ms": 16.64732804179448, "std_tpot_ms": 1.626107485507197, "p99_tpot_ms": 17.97208296168329, "mean_itl_ms": 16.11846741591376, "median_itl_ms": 14.341773930937052, "std_itl_ms": 7.642649831850138, "p99_itl_ms": 57.459484678693144, "mean_e2el_ms": 1380.6941078396449, "median_e2el_ms": 1411.122405086644, "std_e2el_ms": 292.01408153932346, "p99_e2el_ms": 1810.3623394737951}