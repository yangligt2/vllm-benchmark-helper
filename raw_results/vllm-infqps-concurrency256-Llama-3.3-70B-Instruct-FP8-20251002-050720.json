{"date": "20251002-050720", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 1024, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 256, "duration": 8.6628583970014, "completed": 1024, "total_input_tokens": 523265, "total_output_tokens": 30580, "request_throughput": 118.20578763638244, "request_goodput": null, "output_throughput": 3530.0126815630615, "total_token_throughput": 63933.28559909398, "max_output_tokens_per_s": 8008.0, "max_concurrent_requests": 520, "mean_ttft_ms": 1385.6521160678312, "median_ttft_ms": 1349.1159476106986, "std_ttft_ms": 497.63676731205794, "p99_ttft_ms": 2203.092152918689, "mean_tpot_ms": 22.29648770629842, "median_tpot_ms": 23.806763580068946, "std_tpot_ms": 6.749116752564847, "p99_tpot_ms": 33.23916843160983, "mean_itl_ms": 22.247449725854093, "median_itl_ms": 17.34940893948078, "std_itl_ms": 25.423435428446343, "p99_itl_ms": 156.04765750467777, "mean_e2el_ms": 2027.7863678420545, "median_e2el_ms": 2135.7149239629507, "std_e2el_ms": 612.3124068291733, "p99_e2el_ms": 2761.760796161834}