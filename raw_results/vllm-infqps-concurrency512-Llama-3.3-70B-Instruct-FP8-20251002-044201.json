{"date": "20251002-044201", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 2048, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 512, "duration": 15.764288719044998, "completed": 2048, "total_input_tokens": 522240, "total_output_tokens": 123580, "request_throughput": 129.91388552315655, "request_goodput": null, "output_throughput": 7839.237291480315, "total_token_throughput": 40967.27809988523, "max_output_tokens_per_s": 14182.0, "max_concurrent_requests": 909, "mean_ttft_ms": 1372.4900592604854, "median_ttft_ms": 1300.698060891591, "std_ttft_ms": 784.1101418723791, "p99_ttft_ms": 2704.3300211033784, "mean_tpot_ms": 39.79001653721479, "median_tpot_ms": 41.45629636366807, "std_tpot_ms": 7.370363022248324, "p99_tpot_ms": 46.0439247009738, "mean_itl_ms": 39.72672910562118, "median_itl_ms": 34.80895853135735, "std_itl_ms": 29.187699383420522, "p99_itl_ms": 179.18659524060794, "mean_e2el_ms": 3729.9454258516107, "median_e2el_ms": 3988.352786633186, "std_e2el_ms": 1148.815681070589, "p99_e2el_ms": 5339.607177893631}