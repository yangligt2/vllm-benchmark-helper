{"date": "20251002-060245", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 512, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 128, "duration": 11.994462915929034, "completed": 512, "total_input_tokens": 523776, "total_output_tokens": 58707, "request_throughput": 42.686363165127425, "request_goodput": null, "output_throughput": 4894.508442060812, "total_token_throughput": 48562.657959986165, "max_output_tokens_per_s": 6804.0, "max_concurrent_requests": 189, "mean_ttft_ms": 1080.9203089916082, "median_ttft_ms": 1027.7625269955024, "std_ttft_ms": 453.3026556198765, "p99_ttft_ms": 2261.424258686602, "mean_tpot_ms": 14.783447540335715, "median_tpot_ms": 15.103859800546731, "std_tpot_ms": 1.3123630194072087, "p99_tpot_ms": 16.45298208977858, "mean_itl_ms": 14.830430817862904, "median_itl_ms": 13.591677881777287, "std_itl_ms": 6.332756648044966, "p99_itl_ms": 44.784308313392025, "mean_e2el_ms": 2766.578158887569, "median_e2el_ms": 2830.234576482326, "std_e2el_ms": 694.8213335733217, "p99_e2el_ms": 4266.342540844344}