{"date": "20251014-221936", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 40, "duration": 20.40961266902741, "completed": 256, "total_input_tokens": 261888, "total_output_tokens": 51365, "request_throughput": 12.543109178573122, "request_goodput": null, "output_throughput": 2516.706261552377, "total_token_throughput": 15348.306951232682, "max_output_tokens_per_s": 3066.0, "max_concurrent_requests": 69, "mean_ttft_ms": 281.45746078166667, "median_ttft_ms": 233.4407495218329, "std_ttft_ms": 114.31891604170846, "p99_ttft_ms": 602.26849275059, "mean_tpot_ms": 13.600957433599147, "median_tpot_ms": 13.593553801842543, "std_tpot_ms": 1.8657214269465012, "p99_tpot_ms": 21.16210916254202, "mean_itl_ms": 13.43148396752591, "median_itl_ms": 12.496710987761617, "std_itl_ms": 8.80365582614381, "p99_itl_ms": 67.8396077849902, "mean_e2el_ms": 2962.979466326715, "median_e2el_ms": 3447.5949260231573, "std_e2el_ms": 1089.0373339600742, "p99_e2el_ms": 3990.668935654685}