{"date": "20251013-213248", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 60, "duration": 16.298459304030985, "completed": 256, "total_input_tokens": 261888, "total_output_tokens": 50755, "request_throughput": 15.70700611785344, "request_goodput": null, "output_throughput": 3114.098029342388, "total_token_throughput": 19182.365287906458, "max_output_tokens_per_s": 4040.0, "max_concurrent_requests": 98, "mean_ttft_ms": 596.8836310294137, "median_ttft_ms": 449.56001499667764, "std_ttft_ms": 446.9935327769351, "p99_ttft_ms": 2312.4027540441602, "mean_tpot_ms": 14.32742016749134, "median_tpot_ms": 14.588742038148327, "std_tpot_ms": 2.49814787326509, "p99_tpot_ms": 19.68651485687588, "mean_itl_ms": 14.322594031811242, "median_itl_ms": 11.14961999701336, "std_itl_ms": 24.21139446150628, "p99_itl_ms": 117.72219097591001, "mean_e2el_ms": 3422.182785213863, "median_e2el_ms": 3970.848302997183, "std_e2el_ms": 1282.10607487108, "p99_e2el_ms": 5847.150509344643}