{"date": "20251014-222104", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 60, "duration": 14.587300654035062, "completed": 256, "total_input_tokens": 261888, "total_output_tokens": 50707, "request_throughput": 17.549511460105997, "request_goodput": null, "output_throughput": 3476.105771904667, "total_token_throughput": 21429.2559955931, "max_output_tokens_per_s": 4484.0, "max_concurrent_requests": 99, "mean_ttft_ms": 307.5174949290158, "median_ttft_ms": 234.811031492427, "std_ttft_ms": 141.76093386257688, "p99_ttft_ms": 618.2960437028667, "mean_tpot_ms": 13.953815409089042, "median_tpot_ms": 14.021823874319075, "std_tpot_ms": 2.148324765956986, "p99_tpot_ms": 16.61733503569513, "mean_itl_ms": 13.883405516664812, "median_itl_ms": 13.056610012426972, "std_itl_ms": 6.725712808794199, "p99_itl_ms": 36.56953849713318, "mean_e2el_ms": 3043.5784324420183, "median_e2el_ms": 3642.934311501449, "std_e2el_ms": 1171.5623555102075, "p99_e2el_ms": 4299.081031943206}