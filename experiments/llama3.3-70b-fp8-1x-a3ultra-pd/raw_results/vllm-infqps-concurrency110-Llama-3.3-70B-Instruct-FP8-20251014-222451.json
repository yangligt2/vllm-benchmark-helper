{"date": "20251014-222451", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 440, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 110, "duration": 16.605445212044287, "completed": 440, "total_input_tokens": 450120, "total_output_tokens": 87198, "request_throughput": 26.497332313671333, "request_goodput": null, "output_throughput": 5251.16905247162, "total_token_throughput": 32357.940009357393, "max_output_tokens_per_s": 7857.0, "max_concurrent_requests": 177, "mean_ttft_ms": 359.4972352083212, "median_ttft_ms": 292.2953749948647, "std_ttft_ms": 184.17980553997614, "p99_ttft_ms": 775.6885953596794, "mean_tpot_ms": 17.70273093915748, "median_tpot_ms": 16.14101586861116, "std_tpot_ms": 5.917093037505524, "p99_tpot_ms": 46.71858866629189, "mean_itl_ms": 17.066355586966186, "median_itl_ms": 13.63133397535421, "std_itl_ms": 15.022149814146248, "p99_itl_ms": 78.48175082297494, "mean_e2el_ms": 3724.5943814673496, "median_e2el_ms": 4261.529673531186, "std_e2el_ms": 1469.8817630780204, "p99_e2el_ms": 5932.734483727836}