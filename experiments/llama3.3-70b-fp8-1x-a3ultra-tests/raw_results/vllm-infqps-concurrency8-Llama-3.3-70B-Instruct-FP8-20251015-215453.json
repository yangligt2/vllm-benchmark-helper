{"date": "20251015-215453", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "tokenizer_id": "nvidia/Llama-3.3-70B-Instruct-FP8", "num_prompts": 256, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": 8, "duration": 72.15955126000335, "completed": 256, "total_input_tokens": 261888, "total_output_tokens": 51899, "request_throughput": 3.547693902330236, "request_goodput": null, "output_throughput": 719.2256478009255, "total_token_throughput": 4348.5165098847565, "max_output_tokens_per_s": 864.0, "max_concurrent_requests": 17, "mean_ttft_ms": 343.2960029522292, "median_ttft_ms": 324.73291200585663, "std_ttft_ms": 81.72611499457625, "p99_ttft_ms": 620.769789561745, "mean_tpot_ms": 9.224563954016325, "median_tpot_ms": 9.304094165697196, "std_tpot_ms": 0.5317670763431868, "p99_tpot_ms": 9.403477556298158, "mean_itl_ms": 9.301769615723536, "median_itl_ms": 9.244847984518856, "std_itl_ms": 3.816002819424244, "p99_itl_ms": 17.577661499381083, "mean_e2el_ms": 2219.7459830799744, "median_e2el_ms": 2681.3754370086826, "std_e2el_ms": 771.4809124272309, "p99_e2el_ms": 2944.190918336971}